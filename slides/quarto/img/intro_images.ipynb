{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "custom_params = {\n",
        "#    'figure.figsize': (4, 1.2),  # Width, Height in inches\n",
        "#    'font.size': 12,           # Default font size\n",
        "    'axes.grid': True,         # Always show grid\n",
        "}\n",
        "plt.rcParams.update(custom_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false \n",
        "sizes = np.array([50.0, 75.5, 99.3, 149.8, 190.4, 200.8, 200.0, 300.0])\n",
        "prices = np.array([83.3, 125.3, 189.2, 295.1, 644.0, 660.8, 693.6, 1189.5])\n",
        "\n",
        "# Linear fit\n",
        "coef = np.polyfit(sizes, prices, 2)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.title(\"Real estate application\")\n",
        "plt.scatter(sizes, prices, label=\"Data\")\n",
        "\n",
        "x_line = np.linspace(sizes.min(), sizes.max(), 100)\n",
        "y_line = np.polyval(coef, x_line)\n",
        "plt.plot(x_line, y_line, color=\"black\", label=\"Model\")\n",
        "\n",
        "plt.xlabel(\"House size ($\\\\mathrm{m}^2$)\")\n",
        "plt.ylabel(\"Price [kEUR]\")\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| echo: false\n",
        "n_x = 2 # number of inputs\n",
        "n_y = 1 # number of outputs\n",
        "a = -2.0 # lower bound x_1/x_2\n",
        "b = 2.0 # upper bound x_1/x_2\n",
        "n_samples = 500 # number of samples in the training/test datasets\n",
        "sigma_e = 0.1 # standard deviation of the noise\n",
        "grid_points = 100 # number of points in the grid for the plot\n",
        "\n",
        "\n",
        "def f(x):\n",
        "    return 2*np.sin(x[..., 0])  - 3*np.cos(x[..., 1]) # ellipses used to handle an optional \"batch\" dimension\n",
        "# f(np.tensor([0.2, 0.4])), 2*np.sin(0.2) - 3*np.cos(0.4) # test\n",
        "\n",
        "\n",
        "x1_train = a + np.random.rand(n_samples)*(b - a)\n",
        "x2_train = a + np.random.rand(n_samples)*(b - a)\n",
        "X_train = np.stack([x1_train, x2_train], axis=-1)\n",
        "\n",
        "y_train = f(X_train) + sigma_e * np.random.randn(n_samples)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "X_train.shape, y_train.shape \n",
        "\n",
        "x1_test = a + np.random.rand(n_samples)*(b - a)\n",
        "x2_test = a + np.random.rand(n_samples)*(b - a)\n",
        "X_test = np.stack([x1_test, x2_test], axis=-1)\n",
        "\n",
        "y_test = f(X_test) + sigma_e * np.random.randn(n_samples)\n",
        "y_test = y_test.reshape(-1, 1)\n",
        "X_test.shape, y_test.shape \n",
        "\n",
        "## visualization\n",
        "x1_grid = np.linspace(a, b, grid_points)\n",
        "x2_grid = np.linspace(a, b, grid_points)\n",
        "X1_mesh, X2_mesh = np.meshgrid(x1_grid, x2_grid)\n",
        "X_grid = np.c_[X1_mesh.ravel(), X2_mesh.ravel()]\n",
        "y_grid = f(X_grid)\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.plot_surface(X1_mesh, X2_mesh, y_grid.reshape(100, 100), cmap='coolwarm', alpha=0.7)#, edgecolor='none')\n",
        "ax1.set_xlabel(\"$x_1$\")\n",
        "ax1.set_ylabel(\"$x_2$\")\n",
        "ax1.scatter(X_train[:, 0], X_train[:, 1], y_train[:, 0], color='k', s=10)\n",
        "ax1.legend()\n",
        "ax1.set_zlabel(\"$y$\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize all parameters and organize them in a dictionary\n",
        "\n",
        "import jax\n",
        "import jax.random as jr\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "\n",
        "key = jr.key(4)\n",
        "key_W1, key_b1, key_W2, key_b2, key_W3, key_b3 = jr.split(key, 6)\n",
        "nx = 2; ny = 1; nh = 16\n",
        "hidden_size = [16, 8]\n",
        "\n",
        "params = {\n",
        "  \"W1\": jr.normal(key_W1, shape=(hidden_size[0], nx)),\n",
        "  \"b1\": jr.normal(key_b1, shape=(hidden_size[0],)),\n",
        "  \"W2\": jr.normal(key_W2, shape=(hidden_size[1], hidden_size[0])),\n",
        "  \"b2\": jr.normal(key_b2, shape=(hidden_size[1],)),\n",
        "  \"W3\": jr.normal(key_W3, shape=(ny, hidden_size[1])),\n",
        "  \"b3\": jr.normal(key_b3, shape=(ny,)),\n",
        "}\n",
        "\n",
        "def neural_net(params, x):\n",
        "    h1 = jnp.tanh(jnp.dot(params[\"W1\"], x) + params[\"b1\"])\n",
        "    h2 = jnp.tanh(jnp.dot(params[\"W2\"], h1) + params[\"b2\"])\n",
        "    y = jnp.dot(params[\"W3\"], h2) + params[\"b3\"]\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_net(params, X_train[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batched_neural_net = jax.vmap(neural_net, in_axes=(None, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batched_neural_net(params, X_train).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_fn(params, y, x):\n",
        "    y_pred = batched_neural_net(params, x)\n",
        "    return jnp.mean((y - y_pred) ** 2)\n",
        "\n",
        "loss_grad_fn = jax.jit(jax.value_and_grad(loss_fn, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_grad_fn(params, y_train, X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr = 1e-2\n",
        "iters = 5000\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = optax.adam(learning_rate=lr)\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "# Training loop\n",
        "LOSS = []\n",
        "for iter in range(iters):\n",
        "    loss_val, grads = loss_grad_fn(params, y_train, X_train)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    LOSS.append(loss_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(LOSS);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred = batched_neural_net(params, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "ax[0].set_title(\"Test residual plot\")\n",
        "ax[0].plot(y_test, y_test_pred, 'C0o')\n",
        "ax[0].plot(y_test, y_test - y_test_pred, 'ro')\n",
        "ax[1].set_title(\"Test residuals histogram\")\n",
        "ax[1].hist(y_test - y_test_pred);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_grid = batched_neural_net(params, X_grid).squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3D Plot of True Function\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.plot_surface(X1_mesh, X2_mesh, y_grid.reshape(grid_points, grid_points), cmap='coolwarm', edgecolor='none')\n",
        "ax1.set_title(\"True Function\")\n",
        "ax1.set_xlabel(\"$x_1$\")\n",
        "ax1.set_ylabel(\"$x_2$\")\n",
        "ax1.set_zlabel(\"y\")\n",
        "\n",
        "# 3D Plot of NN Predictions\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "ax2.plot_surface(X1_mesh, X2_mesh, y_pred_grid.reshape(grid_points, grid_points), cmap='coolwarm', edgecolor='none')\n",
        "ax2.set_title(\"NN Function\")\n",
        "ax2.set_xlabel(\"$x_1$\")\n",
        "ax2.set_ylabel(\"$x_2$\")\n",
        "ax2.set_zlabel(\"y\");"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
